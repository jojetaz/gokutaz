

# https://arxiv.org/pdf/2502.04896  Table 1
model:
  in_channels: 16
  out_channels: 16
  num_attention_heads: 48
  attention_head_dim: 64
  depth: 40
  patch_size: 2
  dropout: 0.0
  cross_attention_dim: 2048
